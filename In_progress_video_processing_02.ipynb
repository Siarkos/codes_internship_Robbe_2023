{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "MOU4185_20230717-1530\n",
      "2\n",
      "/home/david/MyLocalData/Maud/MOU4185/MOU4185_20230717-1530\n",
      "processing folder already exist\n",
      "3\n",
      "/home/david/MyLocalData/Maud/MOU4185/MOU4185_20230717-1530/MOU4185_20230717-1530.avi\n",
      "4\n",
      "/home/david/MyLocalData/Maud/MOU4185/MOU4185_20230717-1530/MOU4185_20230717-1530.avi\n",
      "Video found\n",
      "1\n",
      "Time:  9.602918718999717\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import glob, os, time, datetime\n",
    "import timeit\n",
    "from own_Functions_05_3 import *\n",
    "import matplotlib as mpl\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import colors\n",
    "\n",
    "\n",
    "#video_folder = '/home/david/Documents/DATA/'\n",
    "video_folder = '/home/david/MyLocalData/Maud/'\n",
    "animalname='MOU4185'\n",
    "session_name = 'MOU4185_20230717-1530'\n",
    "\n",
    "reward_mode = \"remaining\"\n",
    "#reward_mode = \"fixed\"\n",
    "#reward_mode = \"linear_increase\"\n",
    "expert_mode = True #set to True if you want additional informations\n",
    "delaiBetweenVideoExperiment = 0 #number of frame before the start of the experiment #only for habitat/depleting protocols \n",
    "timeIntimout = 15 #time (in s) after the start of the experiment \n",
    "exploration_time = 0 #used to show how long the mouse must still explore\n",
    "\n",
    "\n",
    "ShowVideoWhileProcessing=False\n",
    "ShowSubstractedVideo=False\n",
    "\n",
    "TRAPEZE_SIZE = 60 # we determine the width of the trapezes with TRAPEZE_SIZE\n",
    "##create in the MOU folder a new folder with base name of the video to process\n",
    "###########################################################################################################################\n",
    "video_name = session_name + \".avi\"\n",
    "\n",
    "def trapezes_from_patch(patch, width):\n",
    "    \"\"\"\n",
    "    generate the trapezes coordinates surrounding a patch\n",
    "    inputs:\n",
    "    patch - coordinates of a patch [[Xa, Ya], [Xb, Yb], [Xc, Yc], [Xd, Yd]]\n",
    "    width - width of the trapeze in pixels\n",
    "    outputs:\n",
    "    coordinates [[Xa, Ya], [Xb, Yb], [Xc, Yc], [Xd, Yd]] for the 4 trapezes.\n",
    "    \n",
    "    trapezes_from_patch(SWpatch_coords, 200)\n",
    "    \"\"\"\n",
    "    # N = np.array([patch[0], patch[1], [patch[1][0]+width, patch[1][1]-width], [patch[0][0]-width, patch[0][1]-width]], np.int32).reshape((-1,1,2))\n",
    "    # E = np.array([patch[1], patch[2], [patch[2][0]+width, patch[2][1]+width], [patch[1][0]+width, patch[1][1]-width]], np.int32).reshape((-1,1,2))\n",
    "    # S = np.array([patch[2], patch[3], [patch[3][0]-width, patch[3][1]+width], [patch[2][0]+width, patch[2][1]+width]], np.int32).reshape((-1,1,2))\n",
    "    # W = np.array([patch[3], patch[0], [patch[0][0]-width, patch[0][1]-width], [patch[3][0]-width, patch[3][1]+width]], np.int32).reshape((-1,1,2))\n",
    "    N = [patch[0], patch[1], [patch[1][0]+width, patch[1][1]-width], [patch[0][0]-width, patch[0][1]-width]]\n",
    "    E = [patch[1], patch[2], [patch[2][0]+width, patch[2][1]+width], [patch[1][0]+width, patch[1][1]-width]]\n",
    "    S = [patch[2], patch[3], [patch[3][0]-width, patch[3][1]+width], [patch[2][0]+width, patch[2][1]+width]]\n",
    "    W = [patch[3], patch[0], [patch[0][0]-width, patch[0][1]-width], [patch[3][0]-width, patch[3][1]+width]]\n",
    "\n",
    "    return N, E, S, W\n",
    "\n",
    "def reward_trapeze_change(current_line_turn_info, df, do_I_get_water, reward_mode, remaining_rewards, type_of_turn) : \n",
    "    if reward_mode == \"remaining\" :\n",
    "        remaining_rewards = str(df.loc[df.index[current_line_turn_info], \"maxNberOfConsecRewards\"] - df.loc[df.index[current_line_turn_info], \"nberOfConsecRewards\"])\n",
    "        if df.loc[df.index[current_line_turn_info], \"typeOfTurn\"] == \"gogdet\" or df.loc[df.index[current_line_turn_info], \"typeOfTurn\"] == \"gogtet\":\n",
    "            type_of_turn = \"gogtet\"\n",
    "            do_I_get_water = False\n",
    "            remaining_rewards = \"0\"\n",
    "        elif df.loc[df.index[current_line_turn_info], \"typeOfTurn\"] == \"gobdet\" or df.loc[df.index[current_line_turn_info], \"typeOfTurn\"] == \"gobtet\":\n",
    "            type_of_turn = \"gobtet\"\n",
    "            do_I_get_water = False\n",
    "            remaining_rewards = \"0\"\n",
    "\n",
    "    if df.loc[df.index[current_line_turn_info], \"typeOfTurn\"] == \"expl\" :\n",
    "        type_of_turn = \"expl\"\n",
    "        do_I_get_water = False\n",
    "        remaining_rewards = \"0\"\n",
    "    \n",
    "\n",
    "    elif reward_mode == \"linear_increase\": #get the new number of consecutiv rewards around that object\n",
    "        remaining_rewards = df.loc[df.index[current_line_turn_info], \"nberOfConsecRewards\"]\n",
    "    \n",
    "    elif reward_mode == \"fixed\" : #nothing to change when the reward mode is fixed\n",
    "        pass\n",
    "\n",
    "    return do_I_get_water, remaining_rewards, type_of_turn\n",
    "\n",
    "\n",
    "print('1')\n",
    "print(session_name)\n",
    "processed_video_folderPath=video_folder + animalname + '/' + session_name\n",
    "print('2')\n",
    "print(processed_video_folderPath)\n",
    "\n",
    "# if glob.glob(processed_video_folderPath):\n",
    "if os.path.isdir(processed_video_folderPath):\n",
    "    print('processing folder already exist')\n",
    "    input_video_path=processed_video_folderPath + '/' + video_name\n",
    "    print('3')\n",
    "    print(input_video_path)\n",
    "    final_Video_path=input_video_path\n",
    "else:\n",
    "    input_video_path=video_folder + animalname + '/' + video_name\n",
    "    final_Video_path=processed_video_folderPath + '/' + video_name\n",
    "    #print(input_video_path)\n",
    "    os.mkdir(processed_video_folderPath)\n",
    "\n",
    "## the code will generate a processed video in which we can see the video tracking, region of interested visited, and some event (reward delivered etc ..)\n",
    "## this video is saved as \"sessionname_tracked.avi\"\n",
    "\n",
    "output_trackedVideo_name=video_name[:video_name.find('.')] + '_tracked' + video_name[video_name.find('.'):]\n",
    "#print(output_trackedVideo_name)\n",
    "output_trackedVideo_path=processed_video_folderPath + '/' + output_trackedVideo_name\n",
    "#print(output_trackedVideo_path)\n",
    "\n",
    "\n",
    "dfxyt = pd.read_csv(processed_video_folderPath + '/' + session_name + '_centroidTXY.csv')\n",
    "#dfxyt = dfxyt.loc[dfxyt['time'] >= timeIntimout]\n",
    "#get the number of the first frame past the time in Timout in the time that was recorded (which is different that the one obtained by the framerate)\n",
    "index = dfxyt.loc[dfxyt['time'] >= timeIntimout].index[0]\n",
    "\n",
    "#open turnsinfo to get the correct object and direction\n",
    "df = pd.read_csv(processed_video_folderPath + '/' + session_name + '_turnsinfo.csv')\n",
    "df=df.loc[df['time'] >= timeIntimout] # il y a des artefacts sur les premieres secondes de videos, donc il faut les supprimer\n",
    "#df = df.append(df.iloc[-1])\n",
    "\n",
    "current_line_turn_info = -1\n",
    "indexDF = df.index.values[0] - 1\n",
    "last_line = len(df.index) - 2\n",
    "\n",
    "for i in range(indexDF + 1, df.index.values[-1]):#if there is a missing value for ongoingRewardedObject, replace it with either SW or SE, as long as it's not the one where the mouse is\n",
    "    if (type(df['ongoingRewardedObject'][i]) == float) :\n",
    "        df['ongoingRewardedObject'][i] = str([df['currentPatch'][i]]) \n",
    "\n",
    "\n",
    "\n",
    "ongoingRewardedObject = [a.strip(\"]['\").split(', ') for a in df['ongoingRewardedObject']] #change the format of theses variables to be readable\n",
    "ongoingRewardedObject = ongoingRewardedObject + 2 * [ongoingRewardedObject[-1]]\n",
    "ongoingRewardedDirection = [a.strip('][').split(', ') for a in df['ongoingRewardedDirection']]\n",
    "ongoingRewardedDirection = [['COUNTERCLOCKWISE',90] if len(i) == 1 and i[0] == '90' else ['CLOCKWISE', 270] if len(i) == 1 and i[0] == '270' else ['BOTH', 90, 270] for i in ongoingRewardedDirection ]\n",
    "ongoingRewardedDirection.append(ongoingRewardedDirection[-1])\n",
    "\n",
    "\n",
    "\n",
    "start_time = timeit.timeit()\n",
    "\n",
    "# #Add input video directory here (ctrl+c on video and ctrl+v here to copy full directory)\n",
    "# input_video='/home/david/Documents/Python/CorticoStriatalProject/NewCodesVideo/session_20221010-1243__SE.avi'\n",
    "\n",
    "# output_video = input_video[:input_video.find('.')]+'_tracked'+input_video[input_video.find('.'):]\n",
    "\n",
    "\n",
    "print('4')\n",
    "print(input_video_path)\n",
    "\n",
    "if glob.glob(input_video_path):\n",
    "    print('Video found')\n",
    "else :\n",
    "    print('No video found, check input_video_path name')\n",
    "\n",
    "good_object = ongoingRewardedObject[0][0] # with NE = object 3, NW = 4, SE = 1 and SW= 2\n",
    "current_object = ongoingRewardedObject[0][0] #used to know where to plot\n",
    "if reward_mode == \"remaining\" : \n",
    "    #remaining_rewards = str(df.iat[0, 12] - df.iat[0, 11])\n",
    "    remaining_rewards = str(df.loc[df.index[0], \"maxNberOfConsecRewards\"] - df.loc[df.index[0], \"nberOfConsecRewards\"])\n",
    "elif reward_mode == \"fixed\" :\n",
    "    df_session = pd.read_csv(processed_video_folderPath + '/' + session_name + '_sessionparam.csv')\n",
    "    remaining_rewards = df_session.loc[df_session.index[0], \"proba\" + ongoingRewardedObject[0][0]]\n",
    "elif reward_mode == \"linear_increase\" : \n",
    "    remaining_rewards = df.loc[df.index[0], \"nberOfConsecRewards\"]\n",
    "start = timeit.default_timer() #DAVQ: Take the time from computer clock. Will be used to substrsact time (t)\n",
    "\n",
    "\n",
    "\n",
    "# find_go=input_video[input_video.find('__'):-3] # Finds automatically the correct object from the input video name (if follows the format from acquisition code)\n",
    "# good_object = find_go[2:find_go.find('.')]\n",
    "\n",
    "    #DAVQ: Are the zones equal to patches? \n",
    "    # Apparatus divided in 4 Zones: NW, NE, SW, SE as seen from above\n",
    "    #\n",
    "    #  ---------\n",
    "    # ¦ NW ¦ NE ¦\n",
    "    # ¦---------¦\n",
    "    # ¦ SW ¦ SE ¦\n",
    "    #  ---------\n",
    "\n",
    "    # These are the [X, Y] coordinates of the 4 corners of the 4 patches. \n",
    "    # Each zone contains a patch. \n",
    "    #DAVQ: is the patch an object (4 walls)\n",
    "    # A-------B\n",
    "    # ¦       ¦\n",
    "    # ¦       ¦\n",
    "    # D-------C\n",
    "    # Patch_coords = [[Xa, Ya], [Xb, Yb], [Xc, Yc], [Xd, Yd]]\n",
    "    # From these coords, we can use the trapezes_from_patch() function to get the coordinates of the 4 zones surrounding each patch.\n",
    "    # Width of trapezes is TRAPEZE_SIZE\n",
    "    #       ---------------\n",
    "    #      ¦ \\           / ¦\n",
    "    #      ¦   A-------B   ¦\n",
    "    #      ¦   ¦       ¦   ¦\n",
    "    #      ¦   ¦       ¦   ¦\n",
    "    #      ¦   D-------C   ¦\n",
    "    #      ¦ /           \\ ¦\n",
    "    #       ---------------\n",
    "    # \n",
    "\n",
    "\n",
    "\n",
    "#Assign a number to each trapeze. We will use the difference between the value of the current trapeze and the preceding one to check in which direction\n",
    "#the mouse is turning and if it follows the rule a reward will be given\n",
    "\n",
    "current_direction = ongoingRewardedDirection[0][1:]   \n",
    "direction = ongoingRewardedDirection[0][1:]  # direction to get rewards. Based  on function angleBetween. this vector -previsous vector\n",
    "#direction = ['CLOCKWISE',270]\n",
    "\n",
    "cardinalvectors= {'N': (0,1),'E': (1,0),'S': (0,-1),'W': (-1,0)} # those vectors point in the direction of the 4 reward ports from the center of the object\n",
    "   \n",
    "# open video\n",
    "cap = cv2.VideoCapture(input_video_path) #Path define in the first lines\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0) # set the index of the next frame to be read to the one with index 0\n",
    "# out of the box function to compute background\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(varThreshold=16, detectShadows=True) # background elimination\n",
    "\n",
    "\n",
    "# init some variables\n",
    "# we're going to compare the positions of the mice at given frame versus the previous one. The previous one is noted with  \"_\" \n",
    "# and we need to initialise the previous one \n",
    "_x = _y = 0\n",
    "_currentPatch = '',''\n",
    "_currentTrapeze = currentTrapeze = 'none'\n",
    "_rewarded = rewarded = 0.5  #this is the value we set when the mice is outstide the trapeze. (No reward will be delivered)\n",
    "changedTrapeze = False\n",
    "#change = datetime.datetime.now()    # change of patch. #Dav: looks like it is not used\n",
    "change2 = datetime.datetime.now() # change of trapeze\n",
    "#text = \"\"\n",
    "time_save ,x_pos, y_pos = np.array([]) ,np.array([]) ,np.array([])  # Time and position x, y #DAVQ: MAybe consider change the name of the variable time to avoid confusion with python built in functions\n",
    "speed , dist  , conseq , rew = np.array([]) ,np.array([]) ,np.array([]) ,np.array([]) # Used to compute distance at each delta(t), speed and the rewards\n",
    "zone, trapeze = np.array([]) ,np.array([]) \n",
    "\n",
    "t , count_tot, count_conseq = 0, 0 ,0 #time will increment as 1/framerate,  count will +=1 for each reward\n",
    "gtgo_c,gtgo_t, gtbo_c , gtbo_t , btgo_c,  btgo_t, btbo_c , btbo_t= np.array((0,0)) ,np.array((0,0)) ,np.array((0,0)) ,np.array((0,0)) ,np.array((0,0)) ,np.array((0,0)) ,np.array((0,0)) ,np.array((0,0)) \n",
    "btgo_count,gtgo_count,gtbo_count,btbo_count = 0, 0 ,0 ,0\n",
    "exploring = True ; exploration_timer = 0; duration_last_exploration = 0\n",
    "type_of_turn = \"niao\" ; couleur = (0, 255, 0) #initialized as \" not in an object \"\n",
    "\n",
    "# Change to the framerate used for acquisition (i.e the input and output video should have the same duration)\n",
    "resolution = 512,512   # number of pixel on the x and y axes        # Cannot get a higher resolution than the one we saved the video in (i.e can only degrade)\n",
    "### changing the resolution will require to readjust all the dimensions of zones, objects, water port, trapezes. It is recommended to keep 512\n",
    "\n",
    "framerate = int(cap.get(cv2.CAP_PROP_FPS))    # Get video framerate\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))-framerate #-framerate is used to avoid error when we arrive at the end of the video\n",
    "#we should be able to do better. \n",
    "\n",
    "# save video\n",
    "out = cv2.VideoWriter(output_trackedVideo_path, cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), framerate , (resolution))\n",
    "\n",
    "#--------------------------------------------------\n",
    "# position patches & trapezes & water ports\n",
    "#--------------------------------------------------\n",
    "\n",
    "#The patch coodinates in 512*512 pixel resolution. Real values 2048*2048 pixels images value after 4x bigger\n",
    "#DavQ: not clear I though patches were the entire space divided in 4. Where is 0,0 .....\n",
    "# NWpatch_coords = [[104, 125], [173, 125], [173, 201], [104, 201]]#value initialy in place in the code\n",
    "# NEpatch_coords = [[330, 120], [400, 120], [400, 200], [330, 200]]\n",
    "# SWpatch_coords = [[109, 351], [181, 351], [181, 418], [109, 418]]\n",
    "# SEpatch_coords = [[330, 350], [400, 350], [400, 410], [330, 410]]\n",
    "\n",
    "NWpatch_coords = [[104, 125], [173, 125], [173, 201], [104, 201]]#value is for Maud's acquisition code\n",
    "NEpatch_coords = [[330, 120], [400, 120], [400, 200], [330, 200]]\n",
    "SWpatch_coords = [[109, 351], [181, 351], [181, 410], [109, 410]]\n",
    "SEpatch_coords = [[330, 350], [400, 350], [400, 410], [330, 410]]\n",
    "# Resolution = 512,512\n",
    "# NWpatch_coords = [[104, Resolution[1] -  125], [173, Resolution[1] -  125], [173, Resolution[1] -  201], [104, Resolution[1] -  201]]\n",
    "# NEpatch_coords = [[330, Resolution[1] -  120], [400, Resolution[1] -  120], [400, Resolution[1] -  200], [330, Resolution[1] -  200]]\n",
    "# SWpatch_coords = [[109, Resolution[1] -  351], [181, Resolution[1] -  351], [181, Resolution[1] -  410], [109, Resolution[1] -  410]]\n",
    "# SEpatch_coords = [[330, Resolution[1] -  350], [400, Resolution[1] -  350], [400, Resolution[1] -  410], [330, Resolution[1] -  410]]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Convert for use in openCV\n",
    "patchNW = np.array(NWpatch_coords, np.int32).reshape((-1,1,2))\n",
    "patchNE = np.array(NEpatch_coords, np.int32).reshape((-1,1,2))\n",
    "patchSW = np.array(SWpatch_coords, np.int32).reshape((-1,1,2))\n",
    "patchSE = np.array(SEpatch_coords, np.int32).reshape((-1,1,2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Positions of waterports (at the correct pixel number when resolution is 512*512, multiply by 4 each value to get in full 2048*2048 resolution)\n",
    "waterports = {0:(138,121), 1:(182, 163), 2:(138, 205), 3:(96, 163),\n",
    "                    4:(366, 121), 5:(408, 163), 6:(367, 206), 7:(324, 163),\n",
    "                    8:(143, 347), 9:(185, 382), 10:(146, 424), 11:(102, 382),\n",
    "                    12:(364, 348), 13:(404, 385), 14:(363, 426), 15:(322, 385)}\n",
    "# display in red OFF ports\n",
    "poly =  np.array([[20, 15], [20, 24], [29, 31], [44, 31], [51, 24], [51, 9], [44, 0], [29, 0]], np.int32)\n",
    "inverserd_poly = np.array([[51, 15], [51, 24], [42, 31], [29, 31], [20, 24], [20, 9], [29, 0], [42, 0]], np.int32)#the origin is the top left, so use negative values in order to push where the top left of the figure will be\n",
    "#points of the arrow drawing depending on the object\n",
    "arrows_body = {\"NW\" : [(poly + (NWpatch_coords[0][0], int((NWpatch_coords[0][1] * 3 + NWpatch_coords[3][1])/4))).reshape((-1, 1, 2)), (inverserd_poly + (NWpatch_coords[0][0], int((NWpatch_coords[0][1] * 3 + NWpatch_coords[3][1])/4))).reshape((-1, 1, 2))],\n",
    "            \"NE\" : [(poly + (NEpatch_coords[0][0], int((NEpatch_coords[0][1] * 3 + NEpatch_coords[3][1])/4))).reshape((-1, 1, 2)), (inverserd_poly + (NEpatch_coords[0][0], int((NEpatch_coords[0][1] * 3 + NEpatch_coords[3][1])/4))).reshape((-1, 1, 2))],\n",
    "            \"SW\" : [(poly + (SWpatch_coords[0][0], int((SWpatch_coords[0][1] * 3 + SWpatch_coords[3][1])/4))).reshape((-1, 1, 2)), (inverserd_poly + (SWpatch_coords[0][0], int((SWpatch_coords[0][1] * 3 + SWpatch_coords[3][1])/4))).reshape((-1, 1, 2))],\n",
    "            \"SE\" : [(poly + (SEpatch_coords[0][0], int((SEpatch_coords[0][1] * 3 + SEpatch_coords[3][1])/4))).reshape((-1, 1, 2)), (inverserd_poly + (SEpatch_coords[0][0], int((SEpatch_coords[0][1] * 3 + SEpatch_coords[3][1])/4))).reshape((-1, 1, 2))]}\n",
    "\n",
    "reward_position = { \"NW\" : [133, 165],#coordinate on where to indicate a reward\n",
    "                   \"NE\" : [360, 162],\n",
    "                   \"SW\" : [140, 382],\n",
    "                   \"SE\" : [360, 382]}\n",
    "\n",
    "\n",
    "couleur_turn = {\"gogt\" : (101, 208, 134), \"gogd\" : (101, 208, 134), \"gobt\" : (50, 194, 241), \"gobd\" : (50, 194, 241), \"bogt\" : (56, 145, 230), \"bogd\" : (56, 145, 230), #indicate the color of the trapeze depending of the type of turn\n",
    "                \"bobd\" : (0, 0, 204), \"gogdet\" : (224, 84, 119), \"gobdet\" : (136, 35, 239),\n",
    "                \"bobt\" : (0, 0, 204), \"gogtet\" : (224, 84, 119), \"gobtet\" : (136, 35, 239), \"niao\" : (241, 161, 73), \"expl\" : (241, 161, 73)}\n",
    "\n",
    "\n",
    "# Processing loop, open video file, find animal position and see which path it took\n",
    "# Saves all the parameters of interest (position, time, reward, speed ...) and plots a couple of graphs :\n",
    "#2D and 3D path, reward frequency and types of interactions with the apparatus\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(50) :  #try to apply a higher level of background substraction in the first frames to get a quicker detection\n",
    "#     ret, frm = cap.read() \n",
    "\n",
    "#     # resize the frame and the output \n",
    "#     frm = cv2.resize(frm, (resolution), interpolation = cv2.INTER_AREA) \n",
    "#     imgTrack = np.zeros_like(frm)\n",
    "\n",
    "#     # convert to grayscale and add gaussian blur\n",
    "#     frameGray = cv2.cvtColor(frm, cv2.COLOR_BGR2GRAY)  #can be commented if acquisition done in greyscale (it's the case when doing it with python script)\n",
    "#     kernelSize = (25,25)\n",
    "#     frameBlur = cv2.GaussianBlur(frameGray, kernelSize, 0) ## blurring removes details/noise\n",
    "\n",
    "#     # apply the background substraction\n",
    "#     thresh = fgbg.apply(frameBlur,learningRate=0.02) #learning rate == value between 0 and 1 that indicates how fast the background model is learnt. 0 means that the background model is not updated at all, 1 means that the background model is completely reinitialized from the last frame.\n",
    "#     fgmask = cv2.resize(thresh, (resolution)) ## this is only used when display thresh\n",
    "\n",
    "#     # compute center of mass of what's left and get x, y of the centroid\n",
    "#     M = cv2.moments(thresh)\n",
    "#     if M['m00'] == 0: continue\n",
    "#     x = int(M['m10'] / M['m00'])\n",
    "#     y = int(M['m01'] / M['m00'])\n",
    "#     if _x == 0 and _y == 0:  #for the first frame now the previous frame take the current valu\n",
    "#         _x = x\n",
    "#         _y = y\n",
    "        \n",
    "#     #Saves timestamp and position in arrays for later use / save to .csv\n",
    "#     t+=1/framerate\n",
    "#     time=np.append(time,t)\n",
    "#     x_pos=np.append(x_pos,x)\n",
    "#     y_pos=np.append(y_pos,y)\n",
    "\n",
    "#     if ShowVideoWhileProcessing:\n",
    "#         cv2.imshow('frame', frm)  # final frame\n",
    "#     # cv2.imshow('mask', fgmask)  # shape of the mouse as detected after processing\n",
    "\n",
    "#     if ShowSubstractedVideo:\n",
    "#         cv2.imshow(\"__\", thresh)\n",
    "    \n",
    "#     out.write(frm) #saves frame to output video\n",
    "\n",
    "#\n",
    "for i in range(0, delaiBetweenVideoExperiment) :\n",
    "    # get the current frame  \n",
    "    ret, frm = cap.read()\n",
    "\n",
    "    # resize the frame and the output \n",
    "    frm = cv2.resize(frm, (resolution), interpolation = cv2.INTER_AREA) \n",
    "    imgTrack = np.zeros_like(frm)\n",
    "\n",
    "    # convert to grayscale and add gaussian blur\n",
    "    frameGray = cv2.cvtColor(frm, cv2.COLOR_BGR2GRAY)  #can be commented if acquisition done in greyscale (it's the case when doing it with python script)\n",
    "    kernelSize = (25,25)\n",
    "    frameBlur = cv2.GaussianBlur(frameGray, kernelSize, 0) ## blurring removes details/noise\n",
    "\n",
    "    # apply the background substraction\n",
    "    thresh = fgbg.apply(frameBlur,learningRate=0.004) #learning rate == value between 0 and 1 that indicates how fast the background model is learnt. 0 means that the background model is not updated at all, 1 means that the background model is completely reinitialized from the last frame.\n",
    "    fgmask = cv2.resize(thresh, (resolution)) ## this is only used when display thresh\n",
    "\n",
    "    # compute center of mass of what's left and get x, y of the centroid\n",
    "    M = cv2.moments(thresh)\n",
    "    if M['m00'] == 0: continue\n",
    "    x = int(M['m10'] / M['m00'])\n",
    "    y = int(M['m01'] / M['m00'])\n",
    "    if _x == 0 and _y == 0:  #for the first frame now the previous frame take the current valu\n",
    "        _x = x\n",
    "        _y = y\n",
    "        \n",
    "    #Saves timestamp and position in arrays for later use / save to .csv\n",
    "    t+=1/framerate\n",
    "    time_save=np.append(time_save,t)\n",
    "    x_pos=np.append(x_pos,x)\n",
    "    y_pos=np.append(y_pos,y)\n",
    "    \n",
    "    \n",
    "    # plot a red dot at x, y \n",
    "    frm = cv2.circle(frm, (x,y), 7, (0,   0,   255), -1)\n",
    "    thresh = cv2.circle(thresh, (x,y), 7, (255,   255,   255), -1)\n",
    "    # plot the line between 2 successive frames and add it to frame\n",
    "    imgTrack = cv2.addWeighted(np.zeros_like(imgTrack), 0.85, cv2.line(imgTrack, (x,y), (_x,_y), (255, 127, int(cap.get(cv2.CAP_PROP_POS_AVI_RATIO) * 255)), 2, cv2.LINE_AA), 0.98, 0.)\n",
    "    frm = cv2.addWeighted(frm, 0.4, imgTrack, 1.0, 0.)\n",
    "\n",
    "    out.write(frm) #saves frame to output video\n",
    "    \n",
    "    \n",
    "    # show output can be commented or deleted to not see error message\n",
    "    if ShowVideoWhileProcessing:\n",
    "        cv2.imshow('frame', frm)  # final frame\n",
    "    # cv2.imshow('mask', fgmask)  # shape of the mouse as detected after processing\n",
    "\n",
    "    if ShowSubstractedVideo:\n",
    "        cv2.imshow(\"__\", thresh)\n",
    "\n",
    "    # Close session \n",
    "    # not working in notebook\n",
    "    k = cv2.waitKey(5)  \n",
    "    if k == 3:                # stop the output after 3 button presses\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "decalage = 0\n",
    "#for i in range(0,length - delaiBetweenVideoExperiment): \n",
    "for i in range(0,1000): #used for testing or small visionning\n",
    "       \n",
    "    #--------------------------------------------------\n",
    "    # open & process frames & get animal position\n",
    "    #--------------------------------------------------\n",
    "\n",
    "    # get the current frame  \n",
    "    ret, frm = cap.read()\n",
    "\n",
    "    # resize the frame and the output \n",
    "    frm = cv2.resize(frm, (resolution), interpolation = cv2.INTER_AREA) \n",
    "    imgTrack = np.zeros_like(frm)\n",
    "\n",
    "    # convert to grayscale and add gaussian blur\n",
    "    frameGray = cv2.cvtColor(frm, cv2.COLOR_BGR2GRAY)  #can be commented if acquisition done in greyscale (it's the case when doing it with python script)\n",
    "    kernelSize = (25,25)\n",
    "    frameBlur = cv2.GaussianBlur(frameGray, kernelSize, 0) ## blurring removes details/noise\n",
    "\n",
    "    # apply the background substraction\n",
    "    thresh = fgbg.apply(frameBlur,learningRate=0.0004) #learning rate == value between 0 and 1 that indicates how fast the background model is learnt. 0 means that the background model is not updated at all, 1 means that the background model is completely reinitialized from the last frame.\n",
    "    fgmask = cv2.resize(thresh, (resolution)) ## this is only used when display thresh\n",
    "\n",
    "    # compute center of mass of what's left and get x, y of the centroid\n",
    "    M = cv2.moments(thresh)\n",
    "    if M['m00'] == 0:\n",
    "        decalage = decalage +1\n",
    "        continue\n",
    "    # if i < index : \n",
    "    #     x = int(M['m10'] / M['m00'])\n",
    "    #     y = int(M['m01'] / M['m00'])\n",
    "    # else : \n",
    "        #dfi = i - index\n",
    "    try :\n",
    "        x = int(dfxyt.loc[dfxyt.index[i - decalage], 'xposition'])\n",
    "        y = int(dfxyt.loc[dfxyt.index[i - decalage], 'yposition'])\n",
    "    except : continue\n",
    "    if _x == 0 and _y == 0:  #for the first frame now the previous frame take the current valu\n",
    "        _x = x\n",
    "        _y = y\n",
    "        \n",
    "    #Saves timestamp and position in arrays for later use / save to .csv\n",
    "    t+=1/framerate\n",
    "    time_save=np.append(time_save,t)\n",
    "    x_pos=np.append(x_pos,x)\n",
    "    y_pos=np.append(y_pos,y)\n",
    "\n",
    "    \n",
    "\n",
    "    # if dfxyt.loc[dfxyt.index[i], \"xposition\"] != x or dfxyt.loc[dfxyt.index[i], \"yposition\"] != y : \n",
    "    #     print(\"incoherent detection !\")\n",
    "    #     print( f\" ligne {i}, expected xvalue : {dfxyt.loc[dfxyt.index[i], 'xposition']}, obtained value : {x} \\n expected yvalue {dfxyt.loc[dfxyt.index[i], 'yposition']}, obtained : {y}\")\n",
    "    #     #break\n",
    "\n",
    "    \n",
    "    # plot a red dot at x, y \n",
    "    frm = cv2.circle(frm, (x,y), 7, (0,   0,   255), -1)\n",
    "    thresh = cv2.circle(thresh, (x,y), 7, (255,   255,   255), -1)\n",
    "    # plot the line between 2 successive frames and add it to frame\n",
    "    imgTrack = cv2.addWeighted(np.zeros_like(imgTrack), 0.85, cv2.line(imgTrack, (x,y), (_x,_y), (255, 127, int(cap.get(cv2.CAP_PROP_POS_AVI_RATIO) * 255)), 2, cv2.LINE_AA), 0.98, 0.)\n",
    "    frm = cv2.addWeighted(frm, 0.4, imgTrack, 1.0, 0.)\n",
    "\n",
    "\n",
    "    ## number of the frame that is increasing on the upper right corner of the tracked video\n",
    "    frame_number = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    if expert_mode : \n",
    "        cv2.putText(frm, str(frame_number), (400, 30), fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (0,255,255))\n",
    "\n",
    "\n",
    "    \n",
    "    # Determine  in which quandrant/zone  is the mouse \n",
    "    # frame of size (resolution*resolution), so quadrants are of size (resolution/2  * resolution/2)\n",
    "    # we determine the width of the trapezes with TRAPEZE_SIZE\n",
    "\n",
    "    if x <= resolution[0]/2 and y <= resolution[0]/2: #patch NW\n",
    "        currentPatch = patchNW, 'NW'\n",
    "        N, E, S, W = trapezes_from_patch(NWpatch_coords, TRAPEZE_SIZE)\n",
    "    elif x >= resolution[0]/2 and y<=resolution[0]/2: #patch NE\n",
    "        currentPatch = patchNE, 'NE'\n",
    "        N, E, S, W = trapezes_from_patch(NEpatch_coords, TRAPEZE_SIZE)\n",
    "    elif x <=resolution[0]/2 and y>=resolution[0]/2: #patch SW\n",
    "        currentPatch = patchSW, 'SW'\n",
    "        N, E, S, W = trapezes_from_patch(SWpatch_coords, TRAPEZE_SIZE)\n",
    "    elif x >=resolution[0]/2 and y>=resolution[0]/2: #patch SE\n",
    "        currentPatch = patchSE, 'SE'\n",
    "        N, E, S, W = trapezes_from_patch(SEpatch_coords, TRAPEZE_SIZE)\n",
    "    else: print(\"where is the mouse?\", x, y)\n",
    "\n",
    "    # Plot the current patch (rembmer frm is actual frame)\n",
    "    cv2.polylines(frm,[currentPatch[0]],True,(255,0,0), thickness=3)\n",
    "    cv2.polylines(frm,[np.array(N, np.int32).reshape((-1,1,2))],True,(255,0,0), thickness=3)\n",
    "    cv2.polylines(frm,[np.array(E, np.int32).reshape((-1,1,2))],True,(255,0,0), thickness=3)\n",
    "    cv2.polylines(frm,[np.array(S, np.int32).reshape((-1,1,2))],True,(255,0,0), thickness=3)\n",
    "    cv2.polylines(frm,[np.array(W, np.int32).reshape((-1,1,2))],True,(255,0,0), thickness=3)\n",
    "\n",
    "\n",
    "    # In the current patch, determine if the mouse is in one of the trapezes with points_in_polygon()\n",
    "    # If yes, change color/open valve/etc.\n",
    "    if points_in_polygon(N, [[x, y]]): \n",
    "        currentTrapeze = 'N'\n",
    "    if points_in_polygon(E, [[x, y]]): \n",
    "        currentTrapeze = 'E'\n",
    "    if points_in_polygon(S, [[x, y]]): \n",
    "        currentTrapeze = 'S'\n",
    "    if points_in_polygon(W, [[x, y]]): \n",
    "        currentTrapeze = 'W'\n",
    "    if not points_in_polygon(N, [[x, y]]) and not points_in_polygon(E, [[x, y]]) and not points_in_polygon(S, [[x, y]]) and not points_in_polygon(W, [[x, y]]): \n",
    "        currentTrapeze = 'none'\n",
    "        type_of_turn = \"niao\"\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    # detect when zone changes. if change follows task rule, deliver reward\n",
    "    #--------------------------------------------------\n",
    "        \n",
    "    # detect frame when animal changes trapeze and display it\n",
    "    if str(_currentTrapeze) != str(currentTrapeze):\n",
    "        change2 = datetime.datetime.now()\n",
    "        changedTrapeze = True \n",
    "    else:\n",
    "        changedTrapeze = False\n",
    "    # if (datetime.datetime.now() - change2).total_seconds() < 1 and expert_mode: # this is just to display during one second when the animal changed trapeze\n",
    "\n",
    "    cv2.putText(frm, str(df.loc[df.index[current_line_turn_info], \"totalnberOfRewards\"]) + \"/\" + str(indexDF), (50, 10), fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (250,225,100))\n",
    "    if expert_mode : \n",
    "        cv2.putText(frm, currentTrapeze + \" \" +str(df.loc[df.index[current_line_turn_info], \"currentTrapeze\"]), (50, 50), fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (250,225,100)) # we always plot\n",
    "    #the label of the currentTrapeze\n",
    "\n",
    "    # Task rule\n",
    "    # Deliver water when going clockwise or counterclockwise as defined in the first part fo the code\n",
    "    # assign a number for each trapeze, if must go counterclockwise to get reward (3>2>1>0>3 it's -1/-1/-1/-1/-1)\n",
    "    # return true if follows this sequence, else false (e.g arriving from other patch, going clockwise, skipping a trapeze)\n",
    "    # 'none' trapeze (outside of the object) is set to 0.5 so it doesn't interfere with the comparisons\n",
    "\n",
    "    if str(currentTrapeze) == 'none' or str(_currentTrapeze) == 'none':\n",
    "        do_I_get_water = False\n",
    "        conseq=np.append(conseq,0)\n",
    "        \n",
    "        \n",
    "    elif str(currentPatch[1]) == good_object : #if mouse is in the good object\n",
    "        if str(_currentTrapeze) == str(currentTrapeze) : #Mouse was in the same trapeze last frame\n",
    "            do_I_get_water = False\n",
    "\n",
    "          \n",
    "\n",
    "        if changedTrapeze and str(_currentTrapeze) != 'none': # if changed trapeze\n",
    "\n",
    "            \n",
    "            if ShowVideoWhileProcessing or ShowSubstractedVideo:\n",
    "                print('previous and current trapezes')\n",
    "                print(_currentTrapeze,currentTrapeze)\n",
    "                print('turn angle:')\n",
    "                print(angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze]))\n",
    "                print('is angle OK')\n",
    "                print(angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze]) in direction)\n",
    "\n",
    "\n",
    "            if angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze])not in direction:  # wrong turn\n",
    "                do_I_get_water = False\n",
    "                conseq=np.append(conseq,0)                \n",
    "                btgo_c= np.append(btgo_c,btgo_c[-1]+1)\n",
    "                btgo_t= np.append(btgo_t,t)\n",
    "                type_of_turn = \"gobt\"\n",
    "                \n",
    "            if angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze]) in direction:  # ok turn\n",
    "                count_tot+=1\n",
    "                conseq=np.append(conseq,conseq[-1]+1)                \n",
    "                gtgo_c= np.append(gtgo_c,gtgo_c[-1]+1)\n",
    "                gtgo_t= np.append(gtgo_t,t)\n",
    "             \n",
    "                type_of_turn = \"gogt\"\n",
    "                do_I_get_water = True\n",
    "                #the animal did the correct turn, but depending on the version, it does not necessarly get a reward\n",
    "                if reward_mode != \"remaining\" : \n",
    "                    type_of_turn = df.loc[df.index[current_line_turn_info + 1], \"typeOfTurn\"]\n",
    "                    do_I_get_water = df.loc[df.index[current_line_turn_info + 1 ], \"Rewarded\"]\n",
    "                \n",
    "            if angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze])==180:  # opposite side DavQ: useless\n",
    "                do_I_get_water = False\n",
    "                conseq=np.append(conseq,0)\n",
    "                \n",
    "                \n",
    "\n",
    "            #change to the next line of turns_info, as well as good_object and the direction\n",
    "            if i >= index :\n",
    "                \n",
    "                #remaining_rewards = str(df.iat[current_line_turn_info, 12] - df.iat[current_line_turn_info, 11])\n",
    "                current_line_turn_info += 1\n",
    "                current_object = ongoingRewardedObject[current_line_turn_info][0] ; current_direction = ongoingRewardedDirection[current_line_turn_info][1:]\n",
    "                do_I_get_water, remaining_rewards, type_of_turn = reward_trapeze_change(current_line_turn_info, df, do_I_get_water, reward_mode, remaining_rewards, type_of_turn)\n",
    "                indexDF += 1 \n",
    "                \n",
    "                if current_line_turn_info > last_line : \n",
    "                    current_line_turn_info = last_line\n",
    "                    direction = ongoingRewardedDirection[last_line][1:] ;  good_object = ongoingRewardedObject[last_line][0]\n",
    "                else : \n",
    "                    direction = ongoingRewardedDirection[current_line_turn_info + 1][1:] ;  good_object = ongoingRewardedObject[current_line_turn_info + 1][0]\n",
    "                \n",
    "\n",
    "    ## the animal is not around the correct object but can do correct and incorrect turns\n",
    "    elif str(currentPatch[1]) != good_object :\n",
    "        conseq=np.append(conseq,0)\n",
    "        if str(_currentTrapeze) == str(currentTrapeze) : \n",
    "            do_I_get_water = False\n",
    "                       \n",
    "        if changedTrapeze: # if changed trapeze\n",
    "            if angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze])not in direction:  # wrong turn\n",
    "                do_I_get_water = False                                          \n",
    "                btbo_c= np.append(btbo_c,btbo_c[-1]+1)\n",
    "                btbo_t= np.append(btbo_t,t)               \n",
    "                #text = \"wrong turn, bad object \" + str(currentPatch[-1]) + \" \"\n",
    "                type_of_turn = \"bobt\"\n",
    "                \n",
    "            if angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze]) in direction:  # ok turn DavQ we could change to say good turn bad of object\n",
    "                do_I_get_water = False\n",
    "                gtbo_c= np.append(gtbo_c,gtbo_c[-1]+1)\n",
    "                gtbo_t= np.append(gtbo_t,t)           \n",
    "                #text = \"good turn, bad object \" + str(currentPatch[-1]) +\" \"\n",
    "                type_of_turn = \"bogt\"\n",
    "                \n",
    "            if angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze])==180:  # opposite side\n",
    "                do_I_get_water = False\n",
    "                #text = \"skipped one\"\n",
    "\n",
    "            #change to the next line of turns_info, as well as good_object and the direction\n",
    "            if i >= index :\n",
    "\n",
    "                current_line_turn_info += 1\n",
    "                current_object = ongoingRewardedObject[current_line_turn_info][0] ; current_direction = ongoingRewardedDirection[current_line_turn_info][1:]\n",
    "                do_I_get_water, remaining_rewards, type_of_turn = reward_trapeze_change(current_line_turn_info, df, do_I_get_water, reward_mode, remaining_rewards, type_of_turn)\n",
    "                indexDF += 1 \n",
    "                \n",
    "                if current_line_turn_info > last_line : \n",
    "                    current_line_turn_info = last_line\n",
    "                    direction = ongoingRewardedDirection[last_line][1:] ;  good_object = ongoingRewardedObject[last_line][0]\n",
    "                else : \n",
    "                    direction = ongoingRewardedDirection[current_line_turn_info + 1][1:] ;  good_object = ongoingRewardedObject[current_line_turn_info + 1][0]\n",
    "\n",
    "\n",
    "\n",
    "    if currentPatch[1] != _currentPatch[1] and exploration_time > 0:\n",
    "        if not exploring : \n",
    "            exploring = True\n",
    "            exploration_timer = time_save[-1]\n",
    "        if exploration_timer != 0 and (time_save[-1] - exploration_timer) > exploration_time : \n",
    "            duration_last_exploration = round(time_save[-1] - exploration_timer, 2)\n",
    "            exploration_timer = 0\n",
    "                \n",
    "    if do_I_get_water and exploring and exploration_timer == 0: #end the exploration\n",
    "        exploring = False\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    #determine the color of the trapeze the mouse is in depending on the type of the last turn\n",
    "\n",
    "\n",
    "    couleur = couleur_turn[type_of_turn]\n",
    "    \n",
    "    # In the current patch, determine if the mouse is in one of the trapezes with points_in_polygon()\n",
    "    # If yes, change color/open valve/etc.\n",
    "    if currentTrapeze == 'N': \n",
    "        cv2.polylines(frm,[np.array(N, np.int32).reshape((-1,1,2))],True, couleur, thickness=3)\n",
    "        \n",
    "    elif currentTrapeze == 'E': \n",
    "        cv2.polylines(frm,[np.array(E, np.int32).reshape((-1,1,2))],True, couleur, thickness=3)\n",
    "        \n",
    "    elif currentTrapeze == 'S': \n",
    "        cv2.polylines(frm,[np.array(S, np.int32).reshape((-1,1,2))],True, couleur, thickness=3)\n",
    "        \n",
    "    elif currentTrapeze == 'W': \n",
    "        cv2.polylines(frm,[np.array(W, np.int32).reshape((-1,1,2))],True, couleur, thickness=3)\n",
    "          \n",
    "\n",
    "    #plot the position of the waterports\n",
    "    for w in waterports: cv2.circle(frm, waterports[w], 3, (0, 0, 255), thickness=-1, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    if expert_mode : cv2.putText(frm, str(indexDF + 2) , (50, 30), fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (250,225,100)) #write the text\n",
    "\n",
    "    if exploring and exploration_time > 0 and exploration_timer != 0: \n",
    "        cv2.putText(frm, f\"exploring since {round(time_save[-1] - exploration_timer, 2)}s\", (150, 10), fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (250,225,100))\n",
    "    if duration_last_exploration != 0 and exploration_time > 0 : \n",
    "        cv2.putText(frm, f\"last exploration {duration_last_exploration}s\", (150, 50), fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (250,225,100))\n",
    "\n",
    "\n",
    "    \n",
    "    #if the mouse enter the new rewarded object, show its informations instead of those of the last turn\n",
    "    if currentPatch[1] != _currentPatch[1] and currentPatch[1] == good_object : \n",
    "        current_direction = direction\n",
    "        current_object = good_object\n",
    "        if current_line_turn_info < last_line : \n",
    "            if reward_mode == \"remaining\" : \n",
    "                if df.loc[df.index[current_line_turn_info + 1], \"nberOfConsecRewards\"] == 1 :#if this will be the first reward obtained, then the current number of remaining rewards is the maximum\n",
    "                    remaining_rewards = str(df.loc[df.index[current_line_turn_info + 1], \"maxNberOfConsecRewards\"])\n",
    "            elif reward_mode == \"fixed\" : \n",
    "                remaining_rewards = df_session.loc[df_session.index[0], \"proba\" + ongoingRewardedObject[current_line_turn_info + 1][0]]\n",
    "            elif reward_mode == \"linear_increase\" : \n",
    "                remaining_rewards = 0\n",
    "    \n",
    "\n",
    "    if current_direction[0] == 90 : around = 1\n",
    "    else : around = 0\n",
    "    #draw an arrow indicating the direction of the last turn and print the number of reward remaining\n",
    "    if type_of_turn != \"expl\"  and not (type_of_turn == \"niao\" and df.loc[df.index[current_line_turn_info + 1], \"typeOfTurn\"] == \"expl\"): \n",
    "        if reward_mode == \"remaining\" or current_object != \"none\" :\n",
    "            if len(current_direction) == 1 : \n",
    "                frm = cv2.polylines(frm, [arrows_body[current_object][around]],False, color= (255, 255, 255), thickness= 3)# draw the body of the arrow\n",
    "                frm = cv2.line(frm, list(arrows_body[current_object][around][0][0]), list(arrows_body[current_object][around][0][0] + (-5, 5)), color = (255, 255, 255), thickness= 3)#these two draw the head of the arrow\n",
    "                frm = cv2.line(frm, list(arrows_body[current_object][around][0][0]), list(arrows_body[current_object][around][0][0] + (5, 5)), color = (255, 255, 255), thickness= 3)\n",
    "            if  str(currentPatch[1]) == current_object :\n",
    "                cv2.putText(frm, str(remaining_rewards), reward_position[current_object], fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (0,255,255))\n",
    "            if i == 770 :\n",
    "                print(1)\n",
    "        \n",
    "\n",
    "    if do_I_get_water == True :  # save frame when reward was delivered\n",
    "        rew = np.append(rew,1)\n",
    "    else :\n",
    "        rew = np.append(rew,0)\n",
    "    \n",
    "    # end of the operation on the current frame. We now update _x and _y such as for the next frame the current frame is the previous one \n",
    "    _x = x\n",
    "    _y = y\n",
    "    _currentPatch = currentPatch\n",
    "    _currentTrapeze = currentTrapeze\n",
    "    _rewarded = rewarded\n",
    "\n",
    "    \n",
    "    \n",
    "    # print computer_mouse position when click on frame    \n",
    "    # cv2.setMouseCallback(\"frame\", mousePoints)\n",
    "\n",
    "    out.write(frm) #saves frame to output video\n",
    "    \n",
    "    \n",
    "    # show output can be commented or deleted to not see error message\n",
    "    if ShowVideoWhileProcessing:\n",
    "        cv2.imshow('frame', frm)  # final frame\n",
    "    # cv2.imshow('mask', fgmask)  # shape of the mouse as detected after processing\n",
    "\n",
    "    if ShowSubstractedVideo:\n",
    "        cv2.imshow(\"__\", thresh)\n",
    "\n",
    "\n",
    "    #Save the zone and trapeze in which the mouse is at each frame, will be useful to define the transition paths\n",
    "    trapeze=np.append(trapeze,currentTrapeze)\n",
    "    zone=np.append(zone,currentPatch[1])\n",
    "    # Close session \n",
    "    # not working in notebook\n",
    "    k = cv2.waitKey(5)  \n",
    "    if k == 3:                # stop the output after 3 button presses\n",
    "        break\n",
    "    \n",
    "#Release the input and output video and close the display windows\n",
    "cap.release() \n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "stop = timeit.default_timer() \n",
    "print('Time: ', stop - start)\n",
    "\n",
    "#copy orginal video file in the processed folder\n",
    "\n",
    "os.rename(input_video_path,final_Video_path) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
