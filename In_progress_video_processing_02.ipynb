{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "MOU3975_20230318-1737\n",
      "2\n",
      "/localdata/alicedata/MOU3975/MOU3975_20230318-1737\n",
      "processing folder already exist\n",
      "3\n",
      "/localdata/alicedata/MOU3975/MOU3975_20230318-1737/MOU3975_20230318-1737.avi\n",
      "4\n",
      "/localdata/alicedata/MOU3975/MOU3975_20230318-1737/MOU3975_20230318-1737.avi\n",
      "Video found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20185/429423313.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ongoingRewardedObject'][i] = str([df['currentPatch'][i]])\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import glob, os, time, datetime\n",
    "import timeit\n",
    "from own_Functions import *\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#This file creat an overlayer on top of the video showing when the types of turn, the detected position of the mouse, the number of reward remaining/the probability of reward/the number of reward obtained without leaving the object\n",
    "#depending on the reward mode\n",
    "\n",
    "\n",
    "#indicate the folder where your data are, the name of the animal and the session you which to obtained the video for\n",
    "video_folder = '/localdata/alicedata/'\n",
    "animalname='MOU3975'\n",
    "session_name = 'MOU3975_20230318-1737'\n",
    "\n",
    "#indicate which type of display correspond to the task of the mouse\n",
    "reward_mode = \"remaining\" #the number on the object is how many reward remain in the oject\n",
    "#reward_mode = \"fixed\" #the number on the object is the probability to get rewarded\n",
    "#reward_mode = \"linear_increase\" #indicate the number of reward obtained without leaving this object\n",
    "\n",
    "expert_mode = True #set to True if you want additional informations\n",
    "ShowVideoWhileProcessing=False\n",
    "ShowSubstractedVideo=False\n",
    "\n",
    "#information on how to read the video. Take care that this two parameters are the same as they are for the recording\n",
    "delaiBetweenVideoExperiment = 0 #number of frame before the start of the experiment #only for habitat/depleting protocols \n",
    "\n",
    "TRAPEZE_SIZE = 60 # we determine the width of the trapezes with TRAPEZE_SIZE\n",
    "\n",
    "\n",
    "timeIntimout = 0 #time (in s) after the start of the experiment where the tracking should really commence\n",
    "\n",
    "#this parameters help to see the true duration of exploration. However it only works with versions of exploration where the animal had to change object to stop it, and only if all object were rewarded.\n",
    "exploration_time = 0 #used to show how long the mouse must explore after leaving an object \n",
    "###########################################################################################################################\n",
    "video_name = session_name + \".avi\"\n",
    "\n",
    "def trapezes_from_patch(patch, width):\n",
    "    \"\"\"\n",
    "    generate the trapezes coordinates surrounding a patch\n",
    "    inputs:\n",
    "    patch - coordinates of a patch [[Xa, Ya], [Xb, Yb], [Xc, Yc], [Xd, Yd]]\n",
    "    width - width of the trapeze in pixels\n",
    "    outputs:\n",
    "    coordinates [[Xa, Ya], [Xb, Yb], [Xc, Yc], [Xd, Yd]] for the 4 trapezes.\n",
    "    \n",
    "    trapezes_from_patch(SWpatch_coords, 200)\n",
    "    \"\"\"\n",
    "    # N = np.array([patch[0], patch[1], [patch[1][0]+width, patch[1][1]-width], [patch[0][0]-width, patch[0][1]-width]], np.int32).reshape((-1,1,2))\n",
    "    # E = np.array([patch[1], patch[2], [patch[2][0]+width, patch[2][1]+width], [patch[1][0]+width, patch[1][1]-width]], np.int32).reshape((-1,1,2))\n",
    "    # S = np.array([patch[2], patch[3], [patch[3][0]-width, patch[3][1]+width], [patch[2][0]+width, patch[2][1]+width]], np.int32).reshape((-1,1,2))\n",
    "    # W = np.array([patch[3], patch[0], [patch[0][0]-width, patch[0][1]-width], [patch[3][0]-width, patch[3][1]+width]], np.int32).reshape((-1,1,2))\n",
    "    N = [patch[0], patch[1], [patch[1][0]+width, patch[1][1]-width], [patch[0][0]-width, patch[0][1]-width]]\n",
    "    E = [patch[1], patch[2], [patch[2][0]+width, patch[2][1]+width], [patch[1][0]+width, patch[1][1]-width]]\n",
    "    S = [patch[2], patch[3], [patch[3][0]-width, patch[3][1]+width], [patch[2][0]+width, patch[2][1]+width]]\n",
    "    W = [patch[3], patch[0], [patch[0][0]-width, patch[0][1]-width], [patch[3][0]-width, patch[3][1]+width]]\n",
    "\n",
    "    return N, E, S, W\n",
    "\n",
    "def reward_trapeze_change(current_line_turn_info, df, do_I_get_water, reward_mode, remaining_rewards, type_of_turn) : \n",
    "    if reward_mode == \"remaining\" :\n",
    "        remaining_rewards = str(df.loc[df.index[current_line_turn_info], \"maxNberOfConsecRewards\"] - df.loc[df.index[current_line_turn_info], \"nberOfConsecRewards\"])\n",
    "        if df.loc[df.index[current_line_turn_info], \"typeOfTurn\"] == \"gogdet\" or df.loc[df.index[current_line_turn_info], \"typeOfTurn\"] == \"gogtet\":\n",
    "            type_of_turn = \"gogtet\"\n",
    "            do_I_get_water = False\n",
    "            remaining_rewards = \"0\"\n",
    "        elif df.loc[df.index[current_line_turn_info], \"typeOfTurn\"] == \"gobdet\" or df.loc[df.index[current_line_turn_info], \"typeOfTurn\"] == \"gobtet\":\n",
    "            type_of_turn = \"gobtet\"\n",
    "            do_I_get_water = False\n",
    "            remaining_rewards = \"0\"\n",
    "\n",
    "    if df.loc[df.index[current_line_turn_info], \"typeOfTurn\"] == \"expl\" :\n",
    "        type_of_turn = \"expl\"\n",
    "        do_I_get_water = False\n",
    "        remaining_rewards = \"0\"\n",
    "    \n",
    "    if (df.loc[df.index[current_line_turn_info], \"typeOfTurn\"] == \"gogd\" or df.loc[df.index[current_line_turn_info], \"typeOfTurn\"] == \"gogt\") and not df.loc[df.index[current_line_turn_info], \"Rewarded\"]:\n",
    "        type_of_turn = \"gogdnr\"\n",
    "        do_I_get_water = False\n",
    "        remaining_rewards = \"0\"\n",
    "    \n",
    "\n",
    "    elif reward_mode == \"linear_increase\": #get the new number of consecutiv rewards around that object\n",
    "        remaining_rewards = df.loc[df.index[current_line_turn_info], \"nberOfConsecRewards\"]\n",
    "    \n",
    "    elif reward_mode == \"fixed\" : #nothing to change when the reward mode is fixed\n",
    "        pass\n",
    "\n",
    "    return do_I_get_water, remaining_rewards, type_of_turn\n",
    "\n",
    "##create in the MOU folder a new file with base name of the video to process\n",
    "print('1')\n",
    "print(session_name)\n",
    "processed_video_folderPath=video_folder + animalname + '/' + session_name\n",
    "print('2')\n",
    "print(processed_video_folderPath)\n",
    "\n",
    "# if glob.glob(processed_video_folderPath):\n",
    "if os.path.isdir(processed_video_folderPath):\n",
    "    print('processing folder already exist')\n",
    "    input_video_path=processed_video_folderPath + '/' + video_name\n",
    "    print('3')\n",
    "    print(input_video_path)\n",
    "    final_Video_path=input_video_path\n",
    "else:\n",
    "    input_video_path=video_folder + animalname + '/' + video_name\n",
    "    final_Video_path=processed_video_folderPath + '/' + video_name\n",
    "    #print(input_video_path)\n",
    "    os.mkdir(processed_video_folderPath)\n",
    "\n",
    "## the code will generate a processed video in which we can see the video tracking, region of interested visited, and some event (reward delivered etc ..)\n",
    "## this video is saved as \"sessionname_tracked.avi\"\n",
    "\n",
    "output_trackedVideo_name=video_name[:video_name.find('.')] + '_tracked' + video_name[video_name.find('.'):]\n",
    "#print(output_trackedVideo_name)\n",
    "output_trackedVideo_path=processed_video_folderPath + '/' + output_trackedVideo_name\n",
    "#print(output_trackedVideo_path)\n",
    "\n",
    "\n",
    "dfxyt = pd.read_csv(processed_video_folderPath + '/' + session_name + '_centroidTXY.csv')\n",
    "#dfxyt = dfxyt.loc[dfxyt['time'] >= timeIntimout]\n",
    "#get the number of the first frame past the time in Timout in the time that was recorded (which is different that the one obtained by the framerate)\n",
    "index = dfxyt.loc[dfxyt['time'] >= timeIntimout].index[0]\n",
    "\n",
    "#open turnsinfo to get the correct object and direction\n",
    "df = pd.read_csv(processed_video_folderPath + '/' + session_name + '_turnsinfo.csv')\n",
    "df=df.loc[df['time'] >= timeIntimout] # il y a des artefacts sur les premieres secondes de videos, donc il faut les supprimer\n",
    "#df = df.append(df.iloc[-1])\n",
    "\n",
    "current_line_turn_info = -1\n",
    "indexDF = df.index.values[0] - 1\n",
    "last_line = len(df.index) - 2\n",
    "\n",
    "for i in range(indexDF + 1, df.index.values[-1]):#if there is a missing value for ongoingRewardedObject, replace it with either SW or SE, as long as it's not the one where the mouse is\n",
    "    if (type(df['ongoingRewardedObject'][i]) == float) :\n",
    "        df['ongoingRewardedObject'][i] = str([df['currentPatch'][i]]) \n",
    "\n",
    "\n",
    "\n",
    "ongoingRewardedObject = [a.strip(\"]['\").split(', ') for a in df['ongoingRewardedObject']] #change the format of theses variables to be readable\n",
    "ongoingRewardedObject = ongoingRewardedObject + 2 * [ongoingRewardedObject[-1]]\n",
    "ongoingRewardedDirection = [a.strip('][').split(', ') for a in df['ongoingRewardedDirection']]\n",
    "ongoingRewardedDirection = [['COUNTERCLOCKWISE',90] if len(i) == 1 and i[0] == '90' else ['CLOCKWISE', 270] if len(i) == 1 and i[0] == '270' else ['BOTH', 90, 270] for i in ongoingRewardedDirection ]\n",
    "ongoingRewardedDirection.append(ongoingRewardedDirection[-1])\n",
    "\n",
    "\n",
    "\n",
    "start_time = timeit.timeit()\n",
    "\n",
    "# #Add input video directory here (ctrl+c on video and ctrl+v here to copy full directory)\n",
    "# input_video='/home/david/Documents/Python/CorticoStriatalProject/NewCodesVideo/session_20221010-1243__SE.avi'\n",
    "\n",
    "# output_video = input_video[:input_video.find('.')]+'_tracked'+input_video[input_video.find('.'):]\n",
    "\n",
    "\n",
    "print('4')\n",
    "print(input_video_path)\n",
    "\n",
    "if glob.glob(input_video_path):\n",
    "    print('Video found')\n",
    "else :\n",
    "    print('No video found, check input_video_path name')\n",
    "\n",
    "good_object = ongoingRewardedObject[0][0] # with NE = object 3, NW = 4, SE = 1 and SW= 2\n",
    "current_object = ongoingRewardedObject[0][0] #used to know where to plot\n",
    "if reward_mode == \"remaining\" : \n",
    "    #remaining_rewards = str(df.iat[0, 12] - df.iat[0, 11])\n",
    "    remaining_rewards = str(df.loc[df.index[0], \"maxNberOfConsecRewards\"] - df.loc[df.index[0], \"nberOfConsecRewards\"])\n",
    "elif reward_mode == \"fixed\" :\n",
    "    df_session = pd.read_csv(processed_video_folderPath + '/' + session_name + '_sessionparam.csv')\n",
    "    remaining_rewards = df_session.loc[df_session.index[0], \"proba\" + ongoingRewardedObject[0][0]]\n",
    "elif reward_mode == \"linear_increase\" : \n",
    "    remaining_rewards = df.loc[df.index[0], \"nberOfConsecRewards\"]\n",
    "start = timeit.default_timer() #DAVQ: Take the time from computer clock. Will be used to substrsact time (t)\n",
    "\n",
    "\n",
    "\n",
    "# find_go=input_video[input_video.find('__'):-3] # Finds automatically the correct object from the input video name (if follows the format from acquisition code)\n",
    "# good_object = find_go[2:find_go.find('.')]\n",
    "\n",
    "    #DAVQ: Are the zones equal to patches? \n",
    "    # Apparatus divided in 4 Zones: NW, NE, SW, SE as seen from above\n",
    "    #\n",
    "    #  ---------\n",
    "    # ¦ NW ¦ NE ¦\n",
    "    # ¦---------¦\n",
    "    # ¦ SW ¦ SE ¦\n",
    "    #  ---------\n",
    "\n",
    "    # These are the [X, Y] coordinates of the 4 corners of the 4 patches. \n",
    "    # Each zone contains a patch. \n",
    "    #DAVQ: is the patch an object (4 walls)\n",
    "    # A-------B\n",
    "    # ¦       ¦\n",
    "    # ¦       ¦\n",
    "    # D-------C\n",
    "    # Patch_coords = [[Xa, Ya], [Xb, Yb], [Xc, Yc], [Xd, Yd]]\n",
    "    # From these coords, we can use the trapezes_from_patch() function to get the coordinates of the 4 zones surrounding each patch.\n",
    "    # Width of trapezes is TRAPEZE_SIZE\n",
    "    #       ---------------\n",
    "    #      ¦ \\           / ¦\n",
    "    #      ¦   A-------B   ¦\n",
    "    #      ¦   ¦       ¦   ¦\n",
    "    #      ¦   ¦       ¦   ¦\n",
    "    #      ¦   D-------C   ¦\n",
    "    #      ¦ /           \\ ¦\n",
    "    #       ---------------\n",
    "    # \n",
    "\n",
    "\n",
    "\n",
    "#Assign a number to each trapeze. We will use the difference between the value of the current trapeze and the preceding one to check in which direction\n",
    "#the mouse is turning and if it follows the rule a reward will be given\n",
    "\n",
    "current_direction = ongoingRewardedDirection[0][1:]   \n",
    "direction = ongoingRewardedDirection[0][1:]  # direction to get rewards. Based  on function angleBetween. this vector -previsous vector\n",
    "#direction = ['CLOCKWISE',270]\n",
    "\n",
    "cardinalvectors= {'N': (0,1),'E': (1,0),'S': (0,-1),'W': (-1,0)} # those vectors point in the direction of the 4 reward ports from the center of the object\n",
    "   \n",
    "# open video\n",
    "cap = cv2.VideoCapture(input_video_path) #Path define in the first lines\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0) # set the index of the next frame to be read to the one with index 0\n",
    "# out of the box function to compute background\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(varThreshold=16, detectShadows=True) # background elimination\n",
    "\n",
    "\n",
    "# init some variables\n",
    "# we're going to compare the positions of the mice at given frame versus the previous one. The previous one is noted with  \"_\" \n",
    "# and we need to initialise the previous one \n",
    "_x = _y = 0\n",
    "_currentPatch = '',''\n",
    "_currentTrapeze = currentTrapeze = 'none'\n",
    "_rewarded = rewarded = 0.5  #this is the value we set when the mice is outstide the trapeze. (No reward will be delivered)\n",
    "changedTrapeze = False\n",
    "#change = datetime.datetime.now()    # change of patch. #Dav: looks like it is not used\n",
    "change2 = datetime.datetime.now() # change of trapeze\n",
    "#text = \"\"\n",
    "time_save ,x_pos, y_pos = np.array([]) ,np.array([]) ,np.array([])  # Time and position x, y #DAVQ: MAybe consider change the name of the variable time to avoid confusion with python built in functions\n",
    "speed , dist  , conseq , rew = np.array([]) ,np.array([]) ,np.array([]) ,np.array([]) # Used to compute distance at each delta(t), speed and the rewards\n",
    "zone, trapeze = np.array([]) ,np.array([]) \n",
    "\n",
    "t , count_tot, count_conseq = 0, 0 ,0 #time will increment as 1/framerate,  count will +=1 for each reward\n",
    "gtgo_c,gtgo_t, gtbo_c , gtbo_t , btgo_c,  btgo_t, btbo_c , btbo_t= np.array((0,0)) ,np.array((0,0)) ,np.array((0,0)) ,np.array((0,0)) ,np.array((0,0)) ,np.array((0,0)) ,np.array((0,0)) ,np.array((0,0)) \n",
    "btgo_count,gtgo_count,gtbo_count,btbo_count = 0, 0 ,0 ,0\n",
    "exploring = True ; exploration_timer = 0; duration_last_exploration = 0\n",
    "type_of_turn = \"niao\" ; couleur = (0, 255, 0) #initialized as \" not in an object \"\n",
    "\n",
    "# Change to the framerate used for acquisition (i.e the input and output video should have the same duration)\n",
    "resolution = 512,512   # number of pixel on the x and y axes        # Cannot get a higher resolution than the one we saved the video in (i.e can only degrade)\n",
    "### changing the resolution will require to readjust all the dimensions of zones, objects, water port, trapezes. It is recommended to keep 512\n",
    "\n",
    "framerate = int(cap.get(cv2.CAP_PROP_FPS))    # Get video framerate\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))-framerate #-framerate is used to avoid error when we arrive at the end of the video\n",
    "#we should be able to do better. \n",
    "\n",
    "# save video\n",
    "out = cv2.VideoWriter(output_trackedVideo_path, cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), framerate , (resolution))\n",
    "\n",
    "#--------------------------------------------------\n",
    "# position patches & trapezes & water ports\n",
    "#--------------------------------------------------\n",
    "\n",
    "#The patch coodinates in 512*512 pixel resolution. Real values 2048*2048 pixels images value after 4x bigger\n",
    "#DavQ: not clear I though patches were the entire space divided in 4. Where is 0,0 .....\n",
    "# NWpatch_coords = [[104, 125], [173, 125], [173, 201], [104, 201]]#value initialy in place in the code\n",
    "# NEpatch_coords = [[330, 120], [400, 120], [400, 200], [330, 200]]\n",
    "# SWpatch_coords = [[109, 351], [181, 351], [181, 418], [109, 418]]\n",
    "# SEpatch_coords = [[330, 350], [400, 350], [400, 410], [330, 410]]\n",
    "\n",
    "NWpatch_coords = [[104, 125], [173, 125], [173, 201], [104, 201]]#value is for Maud's acquisition code\n",
    "NEpatch_coords = [[330, 120], [400, 120], [400, 200], [330, 200]]\n",
    "SWpatch_coords = [[109, 351], [181, 351], [181, 410], [109, 410]]\n",
    "SEpatch_coords = [[330, 350], [400, 350], [400, 410], [330, 410]]\n",
    "# Resolution = 512,512\n",
    "# NWpatch_coords = [[104, Resolution[1] -  125], [173, Resolution[1] -  125], [173, Resolution[1] -  201], [104, Resolution[1] -  201]]\n",
    "# NEpatch_coords = [[330, Resolution[1] -  120], [400, Resolution[1] -  120], [400, Resolution[1] -  200], [330, Resolution[1] -  200]]\n",
    "# SWpatch_coords = [[109, Resolution[1] -  351], [181, Resolution[1] -  351], [181, Resolution[1] -  410], [109, Resolution[1] -  410]]\n",
    "# SEpatch_coords = [[330, Resolution[1] -  350], [400, Resolution[1] -  350], [400, Resolution[1] -  410], [330, Resolution[1] -  410]]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Convert for use in openCV\n",
    "patchNW = np.array(NWpatch_coords, np.int32).reshape((-1,1,2))\n",
    "patchNE = np.array(NEpatch_coords, np.int32).reshape((-1,1,2))\n",
    "patchSW = np.array(SWpatch_coords, np.int32).reshape((-1,1,2))\n",
    "patchSE = np.array(SEpatch_coords, np.int32).reshape((-1,1,2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Positions of waterports (at the correct pixel number when resolution is 512*512, multiply by 4 each value to get in full 2048*2048 resolution)\n",
    "waterports = {0:(138,121), 1:(182, 163), 2:(138, 205), 3:(96, 163),\n",
    "                    4:(366, 121), 5:(408, 163), 6:(367, 206), 7:(324, 163),\n",
    "                    8:(143, 347), 9:(185, 382), 10:(146, 424), 11:(102, 382),\n",
    "                    12:(364, 348), 13:(404, 385), 14:(363, 426), 15:(322, 385)}\n",
    "# display in red OFF ports\n",
    "poly =  np.array([[20, 15], [20, 24], [29, 31], [44, 31], [51, 24], [51, 9], [44, 0], [29, 0]], np.int32)\n",
    "inverserd_poly = np.array([[51, 15], [51, 24], [42, 31], [29, 31], [20, 24], [20, 9], [29, 0], [42, 0]], np.int32)#the origin is the top left, so use negative values in order to push where the top left of the figure will be\n",
    "#points of the arrow drawing depending on the object\n",
    "arrows_body = {\"NW\" : [(poly + (NWpatch_coords[0][0], int((NWpatch_coords[0][1] * 3 + NWpatch_coords[3][1])/4))).reshape((-1, 1, 2)), (inverserd_poly + (NWpatch_coords[0][0], int((NWpatch_coords[0][1] * 3 + NWpatch_coords[3][1])/4))).reshape((-1, 1, 2))],\n",
    "            \"NE\" : [(poly + (NEpatch_coords[0][0], int((NEpatch_coords[0][1] * 3 + NEpatch_coords[3][1])/4))).reshape((-1, 1, 2)), (inverserd_poly + (NEpatch_coords[0][0], int((NEpatch_coords[0][1] * 3 + NEpatch_coords[3][1])/4))).reshape((-1, 1, 2))],\n",
    "            \"SW\" : [(poly + (SWpatch_coords[0][0], int((SWpatch_coords[0][1] * 3 + SWpatch_coords[3][1])/4))).reshape((-1, 1, 2)), (inverserd_poly + (SWpatch_coords[0][0], int((SWpatch_coords[0][1] * 3 + SWpatch_coords[3][1])/4))).reshape((-1, 1, 2))],\n",
    "            \"SE\" : [(poly + (SEpatch_coords[0][0], int((SEpatch_coords[0][1] * 3 + SEpatch_coords[3][1])/4))).reshape((-1, 1, 2)), (inverserd_poly + (SEpatch_coords[0][0], int((SEpatch_coords[0][1] * 3 + SEpatch_coords[3][1])/4))).reshape((-1, 1, 2))]}\n",
    "\n",
    "reward_position = { \"NW\" : [133, 165],#coordinate on where to indicate a reward\n",
    "                   \"NE\" : [360, 162],\n",
    "                   \"SW\" : [140, 382],\n",
    "                   \"SE\" : [360, 382]}\n",
    "\n",
    "\n",
    "couleur_turn = {\"gogt\" : (101, 208, 134), \"gogd\" : (101, 208, 134), \"gobt\" : (50, 194, 241), \"gobd\" : (50, 194, 241), \"bogt\" : (56, 145, 230), \"bogd\" : (56, 145, 230), #indicate the color of the trapeze depending of the type of turn\n",
    "                \"bobd\" : (0, 0, 204), \"gogdet\" : (224, 84, 119), \"gobdet\" : (136, 35, 239), \"gogdnr\" : (176, 39, 156),\n",
    "                \"bobt\" : (0, 0, 204), \"gogtet\" : (224, 84, 119), \"gobtet\" : (136, 35, 239), \"niao\" : (241, 161, 73), \"expl\" : (241, 161, 73)}\n",
    "\n",
    "\n",
    "# Processing loop, open video file, find animal position and see which path it took\n",
    "# Saves all the parameters of interest (position, time, reward, speed ...) and plots a couple of graphs :\n",
    "#2D and 3D path, reward frequency and types of interactions with the apparatus\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(50) :  #try to apply a higher level of background substraction in the first frames to get a quicker detection\n",
    "#     ret, frm = cap.read() \n",
    "\n",
    "#     # resize the frame and the output \n",
    "#     frm = cv2.resize(frm, (resolution), interpolation = cv2.INTER_AREA) \n",
    "#     imgTrack = np.zeros_like(frm)\n",
    "\n",
    "#     # convert to grayscale and add gaussian blur\n",
    "#     frameGray = cv2.cvtColor(frm, cv2.COLOR_BGR2GRAY)  #can be commented if acquisition done in greyscale (it's the case when doing it with python script)\n",
    "#     kernelSize = (25,25)\n",
    "#     frameBlur = cv2.GaussianBlur(frameGray, kernelSize, 0) ## blurring removes details/noise\n",
    "\n",
    "#     # apply the background substraction\n",
    "#     thresh = fgbg.apply(frameBlur,learningRate=0.02) #learning rate == value between 0 and 1 that indicates how fast the background model is learnt. 0 means that the background model is not updated at all, 1 means that the background model is completely reinitialized from the last frame.\n",
    "#     fgmask = cv2.resize(thresh, (resolution)) ## this is only used when display thresh\n",
    "\n",
    "#     # compute center of mass of what's left and get x, y of the centroid\n",
    "#     M = cv2.moments(thresh)\n",
    "#     if M['m00'] == 0: continue\n",
    "#     x = int(M['m10'] / M['m00'])\n",
    "#     y = int(M['m01'] / M['m00'])\n",
    "#     if _x == 0 and _y == 0:  #for the first frame now the previous frame take the current valu\n",
    "#         _x = x\n",
    "#         _y = y\n",
    "        \n",
    "#     #Saves timestamp and position in arrays for later use / save to .csv\n",
    "#     t+=1/framerate\n",
    "#     time=np.append(time,t)\n",
    "#     x_pos=np.append(x_pos,x)\n",
    "#     y_pos=np.append(y_pos,y)\n",
    "\n",
    "#     if ShowVideoWhileProcessing:\n",
    "#         cv2.imshow('frame', frm)  # final frame\n",
    "#     # cv2.imshow('mask', fgmask)  # shape of the mouse as detected after processing\n",
    "\n",
    "#     if ShowSubstractedVideo:\n",
    "#         cv2.imshow(\"__\", thresh)\n",
    "    \n",
    "#     out.write(frm) #saves frame to output video\n",
    "\n",
    "#\n",
    "for i in range(0, delaiBetweenVideoExperiment) :\n",
    "    # get the current frame  \n",
    "    ret, frm = cap.read()\n",
    "\n",
    "    # resize the frame and the output \n",
    "    frm = cv2.resize(frm, (resolution), interpolation = cv2.INTER_AREA) \n",
    "    imgTrack = np.zeros_like(frm)\n",
    "\n",
    "    # convert to grayscale and add gaussian blur\n",
    "    frameGray = cv2.cvtColor(frm, cv2.COLOR_BGR2GRAY)  #can be commented if acquisition done in greyscale (it's the case when doing it with python script)\n",
    "    kernelSize = (25,25)\n",
    "    frameBlur = cv2.GaussianBlur(frameGray, kernelSize, 0) ## blurring removes details/noise\n",
    "\n",
    "    # apply the background substraction\n",
    "    thresh = fgbg.apply(frameBlur,learningRate=0.004) #learning rate == value between 0 and 1 that indicates how fast the background model is learnt. 0 means that the background model is not updated at all, 1 means that the background model is completely reinitialized from the last frame.\n",
    "    fgmask = cv2.resize(thresh, (resolution)) ## this is only used when display thresh\n",
    "\n",
    "    # compute center of mass of what's left and get x, y of the centroid\n",
    "    M = cv2.moments(thresh)\n",
    "    if M['m00'] == 0: continue\n",
    "    x = int(M['m10'] / M['m00'])\n",
    "    y = int(M['m01'] / M['m00'])\n",
    "    if _x == 0 and _y == 0:  #for the first frame now the previous frame take the current valu\n",
    "        _x = x\n",
    "        _y = y\n",
    "        \n",
    "    #Saves timestamp and position in arrays for later use / save to .csv\n",
    "    t+=1/framerate\n",
    "    time_save=np.append(time_save,t)\n",
    "    x_pos=np.append(x_pos,x)\n",
    "    y_pos=np.append(y_pos,y)\n",
    "    \n",
    "    \n",
    "    # plot a red dot at x, y \n",
    "    frm = cv2.circle(frm, (x,y), 7, (0,   0,   255), -1)\n",
    "    thresh = cv2.circle(thresh, (x,y), 7, (255,   255,   255), -1)\n",
    "    # plot the line between 2 successive frames and add it to frame\n",
    "    imgTrack = cv2.addWeighted(np.zeros_like(imgTrack), 0.85, cv2.line(imgTrack, (x,y), (_x,_y), (255, 127, int(cap.get(cv2.CAP_PROP_POS_AVI_RATIO) * 255)), 2, cv2.LINE_AA), 0.98, 0.)\n",
    "    frm = cv2.addWeighted(frm, 0.4, imgTrack, 1.0, 0.)\n",
    "\n",
    "    out.write(frm) #saves frame to output video\n",
    "    \n",
    "    \n",
    "    # show output can be commented or deleted to not see error message\n",
    "    if ShowVideoWhileProcessing:\n",
    "        cv2.imshow('frame', frm)  # final frame\n",
    "    # cv2.imshow('mask', fgmask)  # shape of the mouse as detected after processing\n",
    "\n",
    "    if ShowSubstractedVideo:\n",
    "        cv2.imshow(\"__\", thresh)\n",
    "\n",
    "    # Close session \n",
    "    # not working in notebook\n",
    "    k = cv2.waitKey(5)  \n",
    "    if k == 3:                # stop the output after 3 button presses\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "decalage = 0\n",
    "for i in range(0,length - delaiBetweenVideoExperiment): \n",
    "#for i in range(0,1000): #used for testing or small visionning\n",
    "       \n",
    "    #--------------------------------------------------\n",
    "    # open & process frames & get animal position\n",
    "    #--------------------------------------------------\n",
    "\n",
    "    # get the current frame  \n",
    "    ret, frm = cap.read()\n",
    "\n",
    "    # resize the frame and the output \n",
    "    frm = cv2.resize(frm, (resolution), interpolation = cv2.INTER_AREA) \n",
    "    imgTrack = np.zeros_like(frm)\n",
    "\n",
    "    # convert to grayscale and add gaussian blur\n",
    "    frameGray = cv2.cvtColor(frm, cv2.COLOR_BGR2GRAY)  #can be commented if acquisition done in greyscale (it's the case when doing it with python script)\n",
    "    kernelSize = (25,25)\n",
    "    frameBlur = cv2.GaussianBlur(frameGray, kernelSize, 0) ## blurring removes details/noise\n",
    "\n",
    "    # apply the background substraction\n",
    "    thresh = fgbg.apply(frameBlur,learningRate=0.0004) #learning rate == value between 0 and 1 that indicates how fast the background model is learnt. 0 means that the background model is not updated at all, 1 means that the background model is completely reinitialized from the last frame.\n",
    "    fgmask = cv2.resize(thresh, (resolution)) ## this is only used when display thresh\n",
    "\n",
    "    # compute center of mass of what's left and get x, y of the centroid\n",
    "    M = cv2.moments(thresh)\n",
    "    if M['m00'] == 0:\n",
    "        decalage = decalage +1\n",
    "        continue\n",
    "    # if i < index : \n",
    "    #     x = int(M['m10'] / M['m00'])\n",
    "    #     y = int(M['m01'] / M['m00'])\n",
    "    # else : \n",
    "        #dfi = i - index\n",
    "    try :\n",
    "        x = int(dfxyt.loc[dfxyt.index[i - decalage], 'xposition'])\n",
    "        y = int(dfxyt.loc[dfxyt.index[i - decalage], 'yposition'])\n",
    "    except : continue\n",
    "    if _x == 0 and _y == 0:  #for the first frame now the previous frame take the current valu\n",
    "        _x = x\n",
    "        _y = y\n",
    "        \n",
    "    #Saves timestamp and position in arrays for later use / save to .csv\n",
    "    t+=1/framerate\n",
    "    time_save=np.append(time_save,t)\n",
    "    x_pos=np.append(x_pos,x)\n",
    "    y_pos=np.append(y_pos,y)\n",
    "\n",
    "    \n",
    "\n",
    "    # if dfxyt.loc[dfxyt.index[i], \"xposition\"] != x or dfxyt.loc[dfxyt.index[i], \"yposition\"] != y : \n",
    "    #     print(\"incoherent detection !\")\n",
    "    #     print( f\" ligne {i}, expected xvalue : {dfxyt.loc[dfxyt.index[i], 'xposition']}, obtained value : {x} \\n expected yvalue {dfxyt.loc[dfxyt.index[i], 'yposition']}, obtained : {y}\")\n",
    "    #     #break\n",
    "\n",
    "    \n",
    "    # plot a red dot at x, y \n",
    "    frm = cv2.circle(frm, (x,y), 7, (0,   0,   255), -1)\n",
    "    thresh = cv2.circle(thresh, (x,y), 7, (255,   255,   255), -1)\n",
    "    # plot the line between 2 successive frames and add it to frame\n",
    "    imgTrack = cv2.addWeighted(np.zeros_like(imgTrack), 0.85, cv2.line(imgTrack, (x,y), (_x,_y), (255, 127, int(cap.get(cv2.CAP_PROP_POS_AVI_RATIO) * 255)), 2, cv2.LINE_AA), 0.98, 0.)\n",
    "    frm = cv2.addWeighted(frm, 0.4, imgTrack, 1.0, 0.)\n",
    "\n",
    "\n",
    "    ## number of the frame that is increasing on the upper right corner of the tracked video\n",
    "    frame_number = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    if expert_mode : \n",
    "        cv2.putText(frm, str(frame_number), (400, 30), fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (0,255,255))\n",
    "\n",
    "\n",
    "    \n",
    "    # Determine  in which quandrant/zone  is the mouse \n",
    "    # frame of size (resolution*resolution), so quadrants are of size (resolution/2  * resolution/2)\n",
    "    # we determine the width of the trapezes with TRAPEZE_SIZE\n",
    "\n",
    "    if x <= resolution[0]/2 and y <= resolution[0]/2: #patch NW\n",
    "        currentPatch = patchNW, 'NW'\n",
    "        N, E, S, W = trapezes_from_patch(NWpatch_coords, TRAPEZE_SIZE)\n",
    "    elif x >= resolution[0]/2 and y<=resolution[0]/2: #patch NE\n",
    "        currentPatch = patchNE, 'NE'\n",
    "        N, E, S, W = trapezes_from_patch(NEpatch_coords, TRAPEZE_SIZE)\n",
    "    elif x <=resolution[0]/2 and y>=resolution[0]/2: #patch SW\n",
    "        currentPatch = patchSW, 'SW'\n",
    "        N, E, S, W = trapezes_from_patch(SWpatch_coords, TRAPEZE_SIZE)\n",
    "    elif x >=resolution[0]/2 and y>=resolution[0]/2: #patch SE\n",
    "        currentPatch = patchSE, 'SE'\n",
    "        N, E, S, W = trapezes_from_patch(SEpatch_coords, TRAPEZE_SIZE)\n",
    "    else: print(\"where is the mouse?\", x, y)\n",
    "\n",
    "    # Plot the current patch (rembmer frm is actual frame)\n",
    "    cv2.polylines(frm,[currentPatch[0]],True,(255,0,0), thickness=3)\n",
    "    cv2.polylines(frm,[np.array(N, np.int32).reshape((-1,1,2))],True,(255,0,0), thickness=3)\n",
    "    cv2.polylines(frm,[np.array(E, np.int32).reshape((-1,1,2))],True,(255,0,0), thickness=3)\n",
    "    cv2.polylines(frm,[np.array(S, np.int32).reshape((-1,1,2))],True,(255,0,0), thickness=3)\n",
    "    cv2.polylines(frm,[np.array(W, np.int32).reshape((-1,1,2))],True,(255,0,0), thickness=3)\n",
    "\n",
    "\n",
    "    # In the current patch, determine if the mouse is in one of the trapezes with points_in_polygon()\n",
    "    # If yes, change color/open valve/etc.\n",
    "    if points_in_polygon(N, [[x, y]]): \n",
    "        currentTrapeze = 'N'\n",
    "    if points_in_polygon(E, [[x, y]]): \n",
    "        currentTrapeze = 'E'\n",
    "    if points_in_polygon(S, [[x, y]]): \n",
    "        currentTrapeze = 'S'\n",
    "    if points_in_polygon(W, [[x, y]]): \n",
    "        currentTrapeze = 'W'\n",
    "    if not points_in_polygon(N, [[x, y]]) and not points_in_polygon(E, [[x, y]]) and not points_in_polygon(S, [[x, y]]) and not points_in_polygon(W, [[x, y]]): \n",
    "        currentTrapeze = 'none'\n",
    "        type_of_turn = \"niao\"\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    # detect when zone changes. if change follows task rule, deliver reward\n",
    "    #--------------------------------------------------\n",
    "        \n",
    "    # detect frame when animal changes trapeze and display it\n",
    "    if str(_currentTrapeze) != str(currentTrapeze):\n",
    "        change2 = datetime.datetime.now()\n",
    "        changedTrapeze = True \n",
    "    else:\n",
    "        changedTrapeze = False\n",
    "    # if (datetime.datetime.now() - change2).total_seconds() < 1 and expert_mode: # this is just to display during one second when the animal changed trapeze\n",
    "\n",
    "    cv2.putText(frm, str(df.loc[df.index[current_line_turn_info], \"totalnberOfRewards\"]) + \"/\" + str(indexDF), (50, 10), fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (250,225,100))\n",
    "    if expert_mode : \n",
    "        cv2.putText(frm, currentTrapeze + \" \" +str(df.loc[df.index[current_line_turn_info], \"currentTrapeze\"]), (50, 50), fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (250,225,100)) # we always plot\n",
    "    #the label of the currentTrapeze\n",
    "\n",
    "    # Task rule\n",
    "    # Deliver water when going clockwise or counterclockwise as defined in the first part fo the code\n",
    "    # assign a number for each trapeze, if must go counterclockwise to get reward (3>2>1>0>3 it's -1/-1/-1/-1/-1)\n",
    "    # return true if follows this sequence, else false (e.g arriving from other patch, going clockwise, skipping a trapeze)\n",
    "    # 'none' trapeze (outside of the object) is set to 0.5 so it doesn't interfere with the comparisons\n",
    "\n",
    "    if str(currentTrapeze) == 'none' or str(_currentTrapeze) == 'none':\n",
    "        do_I_get_water = False\n",
    "        conseq=np.append(conseq,0)\n",
    "        \n",
    "        \n",
    "    elif str(currentPatch[1]) == good_object : #if mouse is in the good object\n",
    "        if str(_currentTrapeze) == str(currentTrapeze) : #Mouse was in the same trapeze last frame\n",
    "            do_I_get_water = False\n",
    "\n",
    "          \n",
    "\n",
    "        if changedTrapeze and str(_currentTrapeze) != 'none': # if changed trapeze\n",
    "\n",
    "            \n",
    "            if ShowVideoWhileProcessing or ShowSubstractedVideo:\n",
    "                print('previous and current trapezes')\n",
    "                print(_currentTrapeze,currentTrapeze)\n",
    "                print('turn angle:')\n",
    "                print(angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze]))\n",
    "                print('is angle OK')\n",
    "                print(angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze]) in direction)\n",
    "\n",
    "\n",
    "            if angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze])not in direction:  # wrong turn\n",
    "                do_I_get_water = False\n",
    "                conseq=np.append(conseq,0)                \n",
    "                btgo_c= np.append(btgo_c,btgo_c[-1]+1)\n",
    "                btgo_t= np.append(btgo_t,t)\n",
    "                type_of_turn = \"gobt\"\n",
    "                \n",
    "            if angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze]) in direction:  # ok turn\n",
    "                count_tot+=1\n",
    "                conseq=np.append(conseq,conseq[-1]+1)                \n",
    "                gtgo_c= np.append(gtgo_c,gtgo_c[-1]+1)\n",
    "                gtgo_t= np.append(gtgo_t,t)\n",
    "             \n",
    "                type_of_turn = \"gogt\"\n",
    "                do_I_get_water = True\n",
    "                #the animal did the correct turn, but depending on the version, it does not necessarly get a reward\n",
    "                if reward_mode != \"remaining\" : \n",
    "                    type_of_turn = df.loc[df.index[current_line_turn_info + 1], \"typeOfTurn\"]\n",
    "                    do_I_get_water = df.loc[df.index[current_line_turn_info + 1 ], \"Rewarded\"]\n",
    "                \n",
    "            if angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze])==180:  # opposite side DavQ: useless\n",
    "                do_I_get_water = False\n",
    "                conseq=np.append(conseq,0)\n",
    "                \n",
    "                \n",
    "\n",
    "            #change to the next line of turns_info, as well as good_object and the direction\n",
    "            if i >= index :\n",
    "                \n",
    "                #remaining_rewards = str(df.iat[current_line_turn_info, 12] - df.iat[current_line_turn_info, 11])\n",
    "                current_line_turn_info += 1\n",
    "                current_object = ongoingRewardedObject[current_line_turn_info][0] ; current_direction = ongoingRewardedDirection[current_line_turn_info][1:]\n",
    "                do_I_get_water, remaining_rewards, type_of_turn = reward_trapeze_change(current_line_turn_info, df, do_I_get_water, reward_mode, remaining_rewards, type_of_turn)\n",
    "                indexDF += 1 \n",
    "                \n",
    "                if current_line_turn_info > last_line : \n",
    "                    current_line_turn_info = last_line\n",
    "                    direction = ongoingRewardedDirection[last_line][1:] ;  good_object = ongoingRewardedObject[last_line][0]\n",
    "                else : \n",
    "                    direction = ongoingRewardedDirection[current_line_turn_info + 1][1:] ;  good_object = ongoingRewardedObject[current_line_turn_info + 1][0]\n",
    "                \n",
    "\n",
    "    ## the animal is not around the correct object but can do correct and incorrect turns\n",
    "    elif str(currentPatch[1]) != good_object :\n",
    "        conseq=np.append(conseq,0)\n",
    "        if str(_currentTrapeze) == str(currentTrapeze) : \n",
    "            do_I_get_water = False\n",
    "                       \n",
    "        if changedTrapeze: # if changed trapeze\n",
    "            if angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze])not in direction:  # wrong turn\n",
    "                do_I_get_water = False                                          \n",
    "                btbo_c= np.append(btbo_c,btbo_c[-1]+1)\n",
    "                btbo_t= np.append(btbo_t,t)               \n",
    "                #text = \"wrong turn, bad object \" + str(currentPatch[-1]) + \" \"\n",
    "                type_of_turn = \"bobt\"\n",
    "                \n",
    "            if angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze]) in direction:  # ok turn DavQ we could change to say good turn bad of object\n",
    "                do_I_get_water = False\n",
    "                gtbo_c= np.append(gtbo_c,gtbo_c[-1]+1)\n",
    "                gtbo_t= np.append(gtbo_t,t)           \n",
    "                #text = \"good turn, bad object \" + str(currentPatch[-1]) +\" \"\n",
    "                type_of_turn = \"bogt\"\n",
    "                \n",
    "            if angle_between(cardinalvectors[currentTrapeze],cardinalvectors[_currentTrapeze])==180:  # opposite side\n",
    "                do_I_get_water = False\n",
    "                #text = \"skipped one\"\n",
    "\n",
    "            #change to the next line of turns_info, as well as good_object and the direction\n",
    "            if i >= index :\n",
    "\n",
    "                current_line_turn_info += 1\n",
    "                current_object = ongoingRewardedObject[current_line_turn_info][0] ; current_direction = ongoingRewardedDirection[current_line_turn_info][1:]\n",
    "                do_I_get_water, remaining_rewards, type_of_turn = reward_trapeze_change(current_line_turn_info, df, do_I_get_water, reward_mode, remaining_rewards, type_of_turn)\n",
    "                indexDF += 1 \n",
    "                \n",
    "                if current_line_turn_info > last_line : \n",
    "                    current_line_turn_info = last_line\n",
    "                    direction = ongoingRewardedDirection[last_line][1:] ;  good_object = ongoingRewardedObject[last_line][0]\n",
    "                else : \n",
    "                    direction = ongoingRewardedDirection[current_line_turn_info + 1][1:] ;  good_object = ongoingRewardedObject[current_line_turn_info + 1][0]\n",
    "\n",
    "\n",
    "\n",
    "    if currentPatch[1] != _currentPatch[1] and exploration_time > 0:\n",
    "        if not exploring : \n",
    "            exploring = True\n",
    "            exploration_timer = time_save[-1]\n",
    "        if exploration_timer != 0 and (time_save[-1] - exploration_timer) > exploration_time : \n",
    "            duration_last_exploration = round(time_save[-1] - exploration_timer, 2)\n",
    "            exploration_timer = 0\n",
    "                \n",
    "    if do_I_get_water and exploring and exploration_timer == 0: #end the exploration\n",
    "        exploring = False\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    #determine the color of the trapeze the mouse is in depending on the type of the last turn\n",
    "\n",
    "\n",
    "    couleur = couleur_turn[type_of_turn]\n",
    "    \n",
    "    # In the current patch, determine if the mouse is in one of the trapezes with points_in_polygon()\n",
    "    # If yes, change color/open valve/etc.\n",
    "    if currentTrapeze == 'N': \n",
    "        cv2.polylines(frm,[np.array(N, np.int32).reshape((-1,1,2))],True, couleur, thickness=3)\n",
    "        \n",
    "    elif currentTrapeze == 'E': \n",
    "        cv2.polylines(frm,[np.array(E, np.int32).reshape((-1,1,2))],True, couleur, thickness=3)\n",
    "        \n",
    "    elif currentTrapeze == 'S': \n",
    "        cv2.polylines(frm,[np.array(S, np.int32).reshape((-1,1,2))],True, couleur, thickness=3)\n",
    "        \n",
    "    elif currentTrapeze == 'W': \n",
    "        cv2.polylines(frm,[np.array(W, np.int32).reshape((-1,1,2))],True, couleur, thickness=3)\n",
    "          \n",
    "\n",
    "    #plot the position of the waterports\n",
    "    for w in waterports: cv2.circle(frm, waterports[w], 3, (0, 0, 255), thickness=-1, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    if expert_mode : cv2.putText(frm, str(indexDF + 2) , (50, 30), fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (250,225,100)) #write the text\n",
    "\n",
    "    if exploring and exploration_time > 0 and exploration_timer != 0: \n",
    "        cv2.putText(frm, f\"exploring since {round(time_save[-1] - exploration_timer, 2)}s\", (150, 10), fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (250,225,100))\n",
    "    if duration_last_exploration != 0 and exploration_time > 0 : \n",
    "        cv2.putText(frm, f\"last exploration {duration_last_exploration}s\", (150, 50), fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (250,225,100))\n",
    "\n",
    "\n",
    "    \n",
    "    #if the mouse enter the new rewarded object, show its informations instead of those of the last turn\n",
    "    if currentPatch[1] != _currentPatch[1] and currentPatch[1] == good_object : \n",
    "        current_direction = direction\n",
    "        current_object = good_object\n",
    "        if current_line_turn_info < last_line : \n",
    "            if reward_mode == \"remaining\" : \n",
    "                if df.loc[df.index[current_line_turn_info + 1], \"nberOfConsecRewards\"] == 1 :#if this will be the first reward obtained, then the current number of remaining rewards is the maximum\n",
    "                    remaining_rewards = str(df.loc[df.index[current_line_turn_info + 1], \"maxNberOfConsecRewards\"])\n",
    "            elif reward_mode == \"fixed\" : \n",
    "                remaining_rewards = df_session.loc[df_session.index[0], \"proba\" + ongoingRewardedObject[current_line_turn_info + 1][0]]\n",
    "            elif reward_mode == \"linear_increase\" : \n",
    "                remaining_rewards = 0\n",
    "    \n",
    "\n",
    "    if current_direction[0] == 90 : around = 1\n",
    "    else : around = 0\n",
    "    #draw an arrow indicating the direction of the last turn and print the number of reward remaining\n",
    "    if type_of_turn != \"expl\"  and not (type_of_turn == \"niao\" and df.loc[df.index[current_line_turn_info + 1], \"typeOfTurn\"] == \"expl\"): \n",
    "        if reward_mode == \"remaining\" or current_object != \"none\" :\n",
    "            if len(current_direction) == 1 : \n",
    "                frm = cv2.polylines(frm, [arrows_body[current_object][around]],False, color= (255, 255, 255), thickness= 3)# draw the body of the arrow\n",
    "                frm = cv2.line(frm, list(arrows_body[current_object][around][0][0]), list(arrows_body[current_object][around][0][0] + (-5, 5)), color = (255, 255, 255), thickness= 3)#these two draw the head of the arrow\n",
    "                frm = cv2.line(frm, list(arrows_body[current_object][around][0][0]), list(arrows_body[current_object][around][0][0] + (5, 5)), color = (255, 255, 255), thickness= 3)\n",
    "            if  str(currentPatch[1]) == current_object :\n",
    "                cv2.putText(frm, str(remaining_rewards), reward_position[current_object], fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.4, color = (0,255,255))\n",
    "            if i == 770 :\n",
    "                print(1)\n",
    "        \n",
    "\n",
    "    if do_I_get_water == True :  # save frame when reward was delivered\n",
    "        rew = np.append(rew,1)\n",
    "    else :\n",
    "        rew = np.append(rew,0)\n",
    "    \n",
    "    # end of the operation on the current frame. We now update _x and _y such as for the next frame the current frame is the previous one \n",
    "    _x = x\n",
    "    _y = y\n",
    "    _currentPatch = currentPatch\n",
    "    _currentTrapeze = currentTrapeze\n",
    "    _rewarded = rewarded\n",
    "\n",
    "    \n",
    "    \n",
    "    # print computer_mouse position when click on frame    \n",
    "    # cv2.setMouseCallback(\"frame\", mousePoints)\n",
    "\n",
    "    out.write(frm) #saves frame to output video\n",
    "    \n",
    "    \n",
    "    # show output can be commented or deleted to not see error message\n",
    "    if ShowVideoWhileProcessing:\n",
    "        cv2.imshow('frame', frm)  # final frame\n",
    "    # cv2.imshow('mask', fgmask)  # shape of the mouse as detected after processing\n",
    "\n",
    "    if ShowSubstractedVideo:\n",
    "        cv2.imshow(\"__\", thresh)\n",
    "\n",
    "\n",
    "    #Save the zone and trapeze in which the mouse is at each frame, will be useful to define the transition paths\n",
    "    trapeze=np.append(trapeze,currentTrapeze)\n",
    "    zone=np.append(zone,currentPatch[1])\n",
    "    # Close session \n",
    "    # not working in notebook\n",
    "    k = cv2.waitKey(5)  \n",
    "    if k == 3:                # stop the output after 3 button presses\n",
    "        break\n",
    "    \n",
    "#Release the input and output video and close the display windows\n",
    "cap.release() \n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "stop = timeit.default_timer() \n",
    "print('Time: ', stop - start)\n",
    "\n",
    "#copy orginal video file in the processed folder\n",
    "\n",
    "os.rename(input_video_path,final_Video_path) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
